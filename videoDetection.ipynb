{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human pose and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement vidéo de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ajnde\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './danse_adrien.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose and Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_landmarks_to_csv(landmarks, frame_number, csv_data):\n",
    "    #print(f\"Landmark coordinates for frame {frame_number}:\")\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        #print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
    "        csv_data.append([frame_number, mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = 0\n",
    "csv_data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    # Draw the pose landmarks on the frame\n",
    "    if result.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Add the landmark coordinates to the list and print them\n",
    "        write_landmarks_to_csv(result.pose_landmarks.landmark, frame_number, csv_data)\n",
    "        frame_number+=1\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('MediaPipe Pose', frame)\n",
    "\n",
    "    # Exit if 'q' keypyt\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csv_data, columns=['Frame number', 'landmarks', 'x', 'y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"x\"]=((df[\"x\"]-df[\"x\"].min())/(df[\"x\"].max()-df[\"x\"].min()))\n",
    "df[\"y\"]=((df[\"y\"]-df[\"y\"].min())/(df[\"y\"].max()-df[\"y\"].min()))\n",
    "df[\"z\"]=((df[\"z\"]-df[\"z\"].min())/(df[\"z\"].max()-df[\"z\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./dance.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison et score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ajnde\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "from dtaidistance import dtw \n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A voir : https://www.theaidream.com/post/dynamic-time-warping-dtw-algorithm-in-time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRef = pd.read_pickle(\"./dance.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "dfTest = pd.read_pickle(\"./image.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95276901244535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "dfRef['x'].corr(dfTest['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.27662788922727, 24.095914384206562)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "s1 = np.array([0.0, 0, 1, 2, 1, 0, 1, 0, 0])\n",
    "s2 = np.array([0.0, 1, 2, 0, 0, 0, 0, 0, 0])\n",
    "d1 = dtw.distance_fast(np.array(dfRef['x']), np.array(dfTest['x']))\n",
    "d2 = dtw.distance_fast(np.array(dfRef['y']), np.array(dfTest['y']))\n",
    "d1, d2 # retorune 0 si les deux séries sont égales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_landmarks(landmarks, csv_data):\n",
    "    #print(f\"Landmark coordinates for frame {frame_number}:\")\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        #print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
    "        csv_data.append([mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la vidéo.\")\n",
    "        return\n",
    "    duration = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS))\n",
    "    cap.release()\n",
    "\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durée de la vidéo: 7 secondes\n"
     ]
    }
   ],
   "source": [
    "video_path = './danse_adrien.mp4'\n",
    "duration_vid = int(get_video_duration(video_path))\n",
    "print(f\"Durée de la vidéo: {duration_vid} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #on prend ici le pose estimation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.505945218266215\n",
      "9.589654306244524\n",
      "8.801088735538173\n",
      "7.629435298372975\n",
      "7.728127989792488\n",
      "8.145590694711942\n",
      "8.547734125443947\n",
      "10.786681532023433\n",
      "9.702418367547208\n",
      "10.319026177454305\n",
      "7.551021886509874\n",
      "8.555146056187708\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "current_seconds_time = int(time.time())\n",
    "frame_number = 0\n",
    "lis = []\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            #'''\n",
    "            #if results.pose_landmarks:\n",
    "             #   write_landmarks_to_csv(result.pose_landmarks.landmark, frame_number, list)\n",
    "              #  frame_number+=1\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            write_landmarks(landmarks, lis)\n",
    "            #print(lis)\n",
    "           \n",
    "                \n",
    "            if (current_seconds_time != int(time.time())):\n",
    "                if (current_seconds_time % duration_vid == 0):\n",
    "                    #write_landmarks(results.pose_landmarks.landmark, lis)\n",
    "                    df = pd.DataFrame(lis, columns=['landmarks', 'x', 'y','z'])\n",
    "                    df[\"x\"]=((df[\"x\"]-df[\"x\"].min())/(df[\"x\"].max()-df[\"x\"].min()))\n",
    "                    df[\"y\"]=((df[\"y\"]-df[\"y\"].min())/(df[\"y\"].max()-df[\"y\"].min()))\n",
    "                    print(dtw.distance_fast(np.array(dfRef['x'], dfRef['y']), np.array(df['x'], df['y'])))\n",
    "                    lis = []\n",
    "                current_seconds_time = int(time.time())\n",
    "            #'''\n",
    "            #landmarks = results.pose_landmarks.landmark\n",
    "            #print(landmarks)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait obtenir un score pour chaque landmarks ou plusieurs pour avoir plus d'info sur une partie du corps du joueur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention pour le temps à la première itération initialiser le temps à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "import keyboard\n",
    "\n",
    "cu = int(time.time())\n",
    "while(True):\n",
    "    if(keyboard.is_pressed('q')):\n",
    "        break \n",
    "\n",
    "    if (cu != int(time.time())):\n",
    "        if (cu % duration_vid == 0):\n",
    "            print(\"ok\")\n",
    "        cu = int(time.time())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.165361391271915\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "print(dtw.distance_fast(np.array(dfRef['x'], dfRef['y']), np.array(df['x'], df['y'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
